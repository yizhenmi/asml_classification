---
title: "Summative assignment for ASML Classification"
author: "Yizhen Mi"
output: html_notebook
---

Download a dataset on hotel bookings.

```{r}
hotels <- read.csv("https://www.louisaslett.com/Courses/MISCADA/hotels.csv", na.strings=c("NULL","NA"))
View(hotels)
```

Let's have a look at the summary of the data.
```{r}
library("skimr")
skim(hotels)
```
```{r}
library(tidyverse)
library(ggplot2)
#install.packages('e1071')
library(e1071)   #library needed to use Naive Bayes algorithm, svm algorithm

library(rpart)   #Decision Tree

#install.packages("rpart.plot")
library(rpart.plot)

#install.packages("randomForest")
library(randomForest)

#install.packages("pROC")
library(pROC) #ROC curve for analysis

#install.packages("caret")
library(caret)

library(dplyr)
library(tidyr)
# install.packages("kableExtra")
library(kableExtra)
library(DT)
# install.packages("MLeval")
library(MLeval)
# install.packages("ggpubr")
library(ggpubr)
# install.packages("plotly")
library(plotly)
```


```{r}
summary(hotels)
```

```{r}
# missing values
# children, agent, company filled with zeros
hotels$children[is.na(hotels$children)] <- 0
hotels$agent[is.na(hotels$agent)] <- 0
hotels$company[is.na(hotels$company)] <- 0

# The country is filled with unknown
hotels$country[is.na(hotels$country)] <- "unknown"

# SC and Undefined mean the same thing
hotels$meal[which(hotels$meal =='Undefined')] <- 'SC'

# The total number of guests at the time of booking must not be zero
# so clear these abnormal data
hotels <- subset(hotels, hotels$adults + hotels$children + hotels$babies != 0)

# The data with a total stay of 0 days needs to be deleted
hotels <- subset(hotels,
                hotels$stays_in_weekend_nights + hotels$stays_in_week_nights != 0)

View(hotels)
```



```{r}
# City Hotel has a much higher overall booking volume and a higher cancellation rate than Resort Hotel.

df <- hotels %>%
  mutate_at(.vars = vars(is_canceled), .fun = as.character)
ggplot(df, aes(x = hotel,fill=is_canceled)) +
  geom_bar() +
  labs(title = "Bar chart of hotel types")+
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}

#  we can see that the majority of bookings were not repeated guests.
dfr <-hotels
dfr[,'is_repeated_guest']<-factor(hotels[,'is_repeated_guest'])
ggplot(dfr,aes(x=is_repeated_guest,fill=is_repeated_guest))+
  geom_bar(stat="count")+theme_minimal()+
  labs(title = "Repeated guest rate")+
theme(plot.title = element_text(hjust = 0.5))

```


```{r}
# customer_type

  ggplot(data=df,aes(x=customer_type,fill=is_canceled))+
  geom_bar()

ggplot(df, aes(x=customer_type, y=adr, colour=customer_type)) + 
  geom_boxplot() + 
  scale_color_brewer(palette = "BrBG") + 
  theme_light() + 
  scale_y_continuous(limits = c(0, 600)) +
  ggtitle("ADR vs. Customer Type") + 
  xlab("Customer Type") + 
  ylab("adr") 
```



```{r}
#国家
top_countries <- hotels %>%
  filter(!is.na(country)) %>%
  group_by(country) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  head(10)

# Create a bar chart
ggplot(top_countries, aes(x = reorder(country, count), y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  labs(title = "Top 10 Countries of Origin for Hotel Customers",
       x = "Country",
       y = "Number of Customers") +
  coord_flip()
```



```{r}
# Correlation coefficient matrix
num_cols <- sapply(hotels, is.numeric)
num_df <- hotels[, num_cols]

cancel_corr<-as.data.frame(abs(cor(hotels$is_canceled,num_df)))
cancel_corr <- data.frame(value = t(cancel_corr)) %>%
  rownames_to_column(var = "variable") %>%
  arrange(desc(value))

cancel_corr
```



```{r}
df <- hotels[, c("is_canceled", "hotel", "lead_time", "arrival_date_month","market_segment",
             "arrival_date_week_number", "arrival_date_day_of_month", "stays_in_weekend_nights",
             "stays_in_week_nights", "adults", "children", "babies", "meal", "distribution_channel",
             "is_repeated_guest", "previous_cancellations", "previous_bookings_not_canceled", "deposit_type", "customer_type", "adr", "required_car_parking_spaces",
             "total_of_special_requests")]
```


```{r}
df<-df%>%
  mutate(
         hotel=as.factor(hotel),      
         is_canceled=as.factor(is_canceled),
         meal=as.factor(meal),
         market_segment=as.factor(market_segment),
         distribution_channel=as.factor(distribution_channel),
         is_repeated_guest=as.factor(is_repeated_guest),
         deposit_type=as.factor(deposit_type),
         customer_type=as.factor(customer_type),
         arrival_date_day_of_month=as.factor(arrival_date_day_of_month),
         arrival_date_month=as.factor(arrival_date_month))
```

```{r}
set.seed(123)   # set a random seed
index <- sample(nrow(df), nrow(df)*0.3) # random selection of indices

test <- df[index, ]     # save 30% as a test dataset
train <- df[-index,]   # save the rest as a train set
```

```{r}
log_model<-glm(is_canceled~.,family="binomial",data=train)
summary(log_model)
```

```{r}
#Predictions for Logistic Regression
test$logit_pred_prob<-predict(log_model,test,type="response")
test$logit_pred_class<-ifelse(test$logit_pred_prob>0.5,"1","0") 

table(test$is_canceled==test$logit_pred_class)

```
```{r}
table(test$logit_pred_class,test$is_canceled, dnn=c("predicted","actual"))
```
```{r}
(20966+7726)/nrow(test)
```

```{r}
train_pred <- ifelse(predict(log_model, train, type = "response") > 0.5, 1, 0)
mean(train_pred == train$is_canceled)

test_pred <- ifelse(predict(log_model, test, type = "response") > 0.5, 1, 0)
mean(test_pred == test$is_canceled)
```


```{r}
#Naive Bayes Model

model_nb <- naiveBayes(is_canceled ~ ., data = train)

model_nb
```


```{r}
#Predictions for Naive Bayes
pred_nb = predict(model_nb, as.data.frame(test))
pred_prob_nb = predict(model_nb, as.data.frame(test), type = "raw")

table(pred_nb,test$is_canceled, dnn=c("predicted","actual"))
```

```{r}
(3305+12997)/nrow(test)
```



```{r}
#Classification Tree
ct_model<-rpart(is_canceled~.,
                      data=train, 
                      method="class", 
                      control=rpart.control(cp=0.03))

rpart.plot(ct_model)
```

```{r}
# Accuracy of the model
test$ct_pred_prob<-predict(ct_model,test)[,2]
test$ct_pred_class<-predict(ct_model,test,type="class")


table(test$is_canceled==test$ct_pred_class)
```
```{r}
#k-cross validation
set.seed(1)   # set a random seed 
full_tree<-rpart(is_canceled~.,
                     data=train, 
                     method="class",
                     control=rpart.control(cp=0, maxdepth = 3))

rpart.plot(full_tree)



printcp(full_tree)   # xerror, xstd - cross validation results
```

```{r}
# Using plotcp(), you can check how the cross-validation error rate changes as the complexity of the model increases.  In this chart, x-axis is model complexity, and y-axis is xerror rate (from cross-validation).  The bars indicate standard deviation.
plotcp(full_tree)
```

```{r}
min_xerror<-full_tree$cptable[which.min(full_tree$cptable[,"xerror"]),]
min_xerror

# prune tree with minimum cp value
min_xerror_tree<-prune(full_tree, cp=min_xerror[1])
rpart.plot(min_xerror_tree)
```
```{r}
#Accuracy of pruned tree
bp_tree<-min_xerror_tree
test$ct_bp_pred_prob<-predict(bp_tree,test)[,2]
test$ct_bp_pred_class=ifelse(test$ct_bp_pred_prob>0.5,"Yes","No")

table(test$ct_bp_pred_class,test$is_canceled, dnn=c("predicted","actual"))
```

```{r}
train_pred <- predict(bp_tree, newdata = train, type = "class")
mean(train_pred == train$is_canceled)
test_pred <- predict(bp_tree, newdata = test, type = "class")
mean(test_pred == test$is_canceled)
```




```{r}
# Random Forest

set.seed(1)
rf<-randomForest(is_canceled~., data=train, ntree=501, importance=TRUE)
rf
```


```{r}
# getting predictions for test data
test$pred <- predict(rf, newdata = test)

# taking a look at the confusion matrix
confusionMatrix(test$pred, test$is_canceled,mode="everything")
```

```{r}
plot(rf, main="Base Model, 70% ")
abline(v=85,col="black")
rf.legend <- if (is.null(rf$test$err.rate)){
  colnames(rf$err.rate)
  }else {colnames(rf$test$err.rate)}

legend("top", cex =0.5, legend=rf.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)
```


```{r}
n<- length(names(train))
rate <-1

for(i in 1:(n-1)){
  set.seed(123)
  rf_train<-randomForest(as.factor(train$is_canceled)~.,data=train,mtry=i,ntree=85)
  rate[i]<-mean(rf_train$err.rate)   # Calculate the mean value of the model misjudgment rate based on OOB data
  print(rf_train)    
}
```

```{r}
rate
plot(rate)
```


```{r}
# explains feature impact on model
varImpPlot(rf,
           main = "Variable Importance for the Model")
```

```{r}
plot(rf,main = "Error rate of random forest")   
```

```{r}
set.seed(123)
rf<-randomForest(is_canceled~., data=train,      
                       ntree=85,    mtry=5,                 
                       importance=TRUE)
rf
```

```{r}
test$rf_pred_prob<-predict(rf,test,type="prob")[,2]   #use a test dataset for model evaluation
test$rf_pred_class<-predict(rf,test,type="class")
```


```{r}
ct_roc<-roc(test$is_canceled,test$ct_bp_pred_prob,auc=TRUE)

logit_roc<-roc(test$is_canceled,test$logit_pred_prob,auc=TRUE)

nb_roc = roc(test$is_canceled,pred_prob_nb[,2],auc=TRUE)
rf_roc<-roc(test$is_canceled,test$rf_pred_prob,auc=TRUE)


plot(logit_roc,print.auc=TRUE,print.auc.y=.4, col="green3")
plot(rf_roc,print.auc=TRUE,print.auc.y=.1,col="orange2",add=TRUE)
plot(nb_roc,print.auc=TRUE,print.auc.y=.3, col="red",add=TRUE)
plot(ct_roc,print.auc=TRUE,print.auc.y=.2, col="blue3",add=TRUE)
legend("topright",                              legend=c("nb","cl","logit","rf"),       
col=c("red","blue3","green3","orange2"),                
lty=1,lwd=2) 
```




```{r}
# getting predictions for test data
test$pred <- predict(rf, newdata = test)

# taking a look at the confusion matrix
confusionMatrix(test$pred, test$is_canceled)
```




```{r}
library(knitr)
DF = data.frame(Model <- c("Logistic Regression","Naive_Bayes", "Classification_Tree", "Random_Forest"),  accuracy<- c(0.8067,0.4583,0.7480,0.8582))

kable(DF, col.names = c("Model","accuracy"))
```


